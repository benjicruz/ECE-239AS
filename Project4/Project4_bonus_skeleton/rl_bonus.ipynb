{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reinforcement Learning Bonus: DDPG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- As before, please do not modify the folder architecture and do not rename some of the files.\n",
        "\n",
        "- You will need to fill in the model.py and DDPG.py to solve the DoublePendulum environment.\n",
        "- Because this is a bonus, there will be no test cases.\n",
        "- This entire part will be worth 5 points of extra credit for project 4, and will be due on the same day as project 4, so June 6th.\n",
        "\n",
        "To avoid pain with installation and model training, we strongly recommend you to use Colab for this project. DO NOT use Windows for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SiaejGWWY2y",
        "outputId": "40b4dcde-3a29-4cee-a102-b3d47e352d59"
      },
      "outputs": [],
      "source": [
        "# mount it if you use Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCo_z0hJWcdZ",
        "outputId": "49491091-1af8-4efb-80d1-23a72d57ce64"
      },
      "outputs": [],
      "source": [
        "# # TODO: change the dir to your folder\n",
        "# %cd /content/drive/MyDrive/YOUR_FOLDER_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H97ykZzFUKJE",
        "outputId": "75197dfe-1236-4fc9-959e-f45b7c2c4787"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%env MUJOCO_GL=egl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOu48qfnUKJj",
        "outputId": "6b083116-bc0a-4502-d947-0167ed8695c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\benji\\anaconda3\\lib\\site-packages (1.24.3)\n",
            "Requirement already satisfied: torch in c:\\users\\benji\\anaconda3\\lib\\site-packages (2.2.1)\n",
            "Requirement already satisfied: wandb in c:\\users\\benji\\anaconda3\\lib\\site-packages (0.19.11)\n",
            "Requirement already satisfied: swig in c:\\users\\benji\\anaconda3\\lib\\site-packages (4.3.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\benji\\anaconda3\\lib\\site-packages (3.8.0)\n",
            "Requirement already satisfied: termcolor in c:\\users\\benji\\anaconda3\\lib\\site-packages (2.4.0)\n",
            "Requirement already satisfied: gymnasium[mujoco] in c:\\users\\benji\\anaconda3\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\benji\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\benji\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\benji\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\benji\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (3.1.37)\n",
            "Requirement already satisfied: platformdirs in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (3.10.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (5.9.0)\n",
            "Requirement already satisfied: pydantic<3 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (1.10.12)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\benji\\anaconda3\\lib\\site-packages (from wandb) (68.2.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from gymnasium[mujoco]) (2.2.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Collecting mujoco>=2.1.5 (from gymnasium[mujoco])\n",
            "  Downloading mujoco-3.3.2-cp311-cp311-win_amd64.whl.metadata (45 kB)\n",
            "     ---------------------------------------- 0.0/45.5 kB ? eta -:--:--\n",
            "     ----------------- -------------------- 20.5/45.5 kB 330.3 kB/s eta 0:00:01\n",
            "     -------------------------------------- 45.5/45.5 kB 451.8 kB/s eta 0:00:00\n",
            "Requirement already satisfied: imageio>=2.14.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from gymnasium[mujoco]) (2.33.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\benji\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: absl-py in c:\\users\\benji\\anaconda3\\lib\\site-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (2.1.0)\n",
            "Collecting etils[epath] (from mujoco>=2.1.5->gymnasium[mujoco])\n",
            "  Downloading etils-1.12.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting glfw (from mujoco>=2.1.5->gymnasium[mujoco])\n",
            "  Downloading glfw-2.9.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-win_amd64.whl.metadata (5.4 kB)\n",
            "Collecting pyopengl (from mujoco>=2.1.5->gymnasium[mujoco])\n",
            "  Downloading PyOpenGL-3.1.9-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\benji\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n",
            "Collecting importlib_resources (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco])\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: zipp in c:\\users\\benji\\anaconda3\\lib\\site-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (3.17.0)\n",
            "Downloading mujoco-3.3.2-cp311-cp311-win_amd64.whl (4.9 MB)\n",
            "   ---------------------------------------- 0.0/4.9 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.3/4.9 MB 9.3 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 1.3/4.9 MB 16.6 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 2.1/4.9 MB 18.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 3.8/4.9 MB 21.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.9/4.9 MB 22.6 MB/s eta 0:00:00\n",
            "Downloading glfw-2.9.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-win_amd64.whl (559 kB)\n",
            "   ---------------------------------------- 0.0/559.4 kB ? eta -:--:--\n",
            "   --------------------------------------- 559.4/559.4 kB 36.6 MB/s eta 0:00:00\n",
            "Downloading PyOpenGL-3.1.9-py3-none-any.whl (3.2 MB)\n",
            "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
            "   -------------------- ------------------- 1.6/3.2 MB 52.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.2/3.2 MB 40.8 MB/s eta 0:00:00\n",
            "Downloading etils-1.12.2-py3-none-any.whl (167 kB)\n",
            "   ---------------------------------------- 0.0/167.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 167.6/167.6 kB 9.8 MB/s eta 0:00:00\n",
            "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: pyopengl, glfw, importlib_resources, etils, mujoco\n",
            "Successfully installed etils-1.12.2 glfw-2.9.0 importlib_resources-6.5.2 mujoco-3.3.2 pyopengl-3.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy torch wandb swig gymnasium[mujoco] matplotlib termcolor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Wz99P9p3UKJo"
      },
      "outputs": [],
      "source": [
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAuMD1BaUKKA"
      },
      "source": [
        "## Introduction to the Enviroment\n",
        "We will be training a DDPG agent to solve the DoublePendulum environment. The DoublePendulum environment is a classic control problem where the goal is to balance a double pendulum on a cart.\n",
        "#### Action Space\n",
        "The agent can apply a force to the cart in the range of -1 to 1. This is a continuous action space.\n",
        "#### Observation Space\n",
        "The observation space is a 9 dimensional vector. The first 1 is the position of the cart, the next 4 are the cosines and sins of different angles of the double pendulum, and the next 3 are the velocities of the cart and the pendulum, and the final 1 is the constrain forces on the cart. You can find more information about these constraint forces [here](https://homes.cs.washington.edu/~todorov/papers/TodorovICRA14.pdf)\n",
        "#### Reward\n",
        "The reward can be decomposed into 3 parts. The first part is an alive bonus that pays +10 for every time step the second pendulum is upright. There are 2 penalty terms, one for the tip of the second pendulum moving too much, and another for the cart moving too fast.\n",
        "\n",
        "You can find more information about the environment [here](https://gymnasium.farama.org/environments/mujoco/inverted_double_pendulum/)\n",
        "\n",
        "First let us visualize the game and understand the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qwr3jfFuUKKD"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvertedDoublePendulum-v5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m env\u001b[38;5;241m.\u001b[39mnp_random \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvertedDoublePendulum-v5\u001b[39m\u001b[38;5;124m\"\u001b[39m, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:704\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m env_spec\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m load_env_creator(env_spec\u001b[38;5;241m.\u001b[39mentry_point)\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# Determine if to use the rendering\u001b[39;00m\n\u001b[0;32m    707\u001b[0m render_modes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:551\u001b[0m, in \u001b[0;36mload_env_creator\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    The environment constructor for the given environment name.\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    550\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 551\u001b[0m mod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(mod_name)\n\u001b[0;32m    552\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MujocoEnv\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmujoco_rendering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MujocoRenderer\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Space\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmujoco\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mDependencyNotInstalled(\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMuJoCo is not installed, run `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgymnasium[mujoco]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     17\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\site-packages\\mujoco\\__init__.py:217\u001b[0m\n\u001b[0;32m    213\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIgnoring non-library in plugin directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    215\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory,\u001b[38;5;250m \u001b[39mfilename)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mImportWarning\u001b[39;00m)\n\u001b[1;32m--> 217\u001b[0m _load_all_bundled_plugins()\n\u001b[0;32m    219\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m mj_versionString()\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\site-packages\\mujoco\\__init__.py:210\u001b[0m, in \u001b[0;36m_load_all_bundled_plugins\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(filename)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.dll\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.dylib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.so\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 210\u001b[0m     PLUGIN_HANDLES\u001b[38;5;241m.\u001b[39mappend(ctypes\u001b[38;5;241m.\u001b[39mCDLL(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)))\n\u001b[0;32m    211\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__init__.py\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Benji\\anaconda3\\Lib\\ctypes\\__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m _dlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, mode)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "env = gym.make(\"InvertedDoublePendulum-v5\")\n",
        "env.np_random = np.random.RandomState(42)\n",
        "\n",
        "eval_env = gym.make(\"InvertedDoublePendulum-v5\", render_mode=\"rgb_array\")\n",
        "eval_env.np_random = np.random.RandomState(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gzTEnD0yUKKD",
        "outputId": "2ad0ccd1-6212-4fe6-9ab5-1ef313dc6507"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "frames = []\n",
        "s, _ = eval_env.reset()\n",
        "\n",
        "while True:\n",
        "    a = eval_env.action_space.sample()\n",
        "    s, r, terminated, truncated, _ = eval_env.step(a)\n",
        "    frames.append(eval_env.render())\n",
        "    if terminated or truncated:\n",
        "        break\n",
        "\n",
        "anim = animate(frames)\n",
        "HTML(anim.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBfF0XtUUKKE"
      },
      "source": [
        "## Model (1 point)\n",
        "Because the inputs to the model is a 9 dimensional vector, we will use a MLP. Specifically we will follow the architecture in the DDPG paper. For DDPG we have both an Actor and a Critic. The Actor is responsible for selecting the action, and the Critic is responsible for evaluating the action.\n",
        "#### Actor\n",
        "The Actor is a 3 layer MLP:\n",
        "- Layer 1: 400 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in)\n",
        "- Layer 2: 300 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in)\n",
        "- Layer 3: 1 unit, tanh activation, intialized with uniform weights in the range of -0.003 to 0.003\n",
        "#### Critic\n",
        "The Critic is a 3 layer MLP:\n",
        "- Layer 1: 400 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in)\n",
        "- Layer 2: 300 units, ReLU activation, Fan-in weight initialization, ie each weight is initialized with a uniform distribution in the range of -1/sqrt(fan_in) to 1/sqrt(fan_in). Input is the concatenation of the 400 dimension embedding from the state, and the action taken.\n",
        "- Layer 3: 1 unit, intialized with uniform weights in the range of -0.003 to 0.003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEBMCPWTUKKI"
      },
      "outputs": [],
      "source": [
        "import model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRC-IC4TUKKI"
      },
      "source": [
        "## Exploration (1 point)\n",
        "Because DDPG is an off policy algorithm, we will use a noise process to encourage exploration. Specifically we will use the Ornstein-Uhlenbeck process. The Ornstein-Uhlenbeck process is a stochastic process that generates temporally correlated noise. The process is defined by the following stochastic differential equation:\n",
        "$$dx_t = \\theta(\\mu - x_t)dt + \\sigma dW_t$$\n",
        "Where $\\theta$ is the rate of mean reversion, $\\mu$ is the long run mean of the process, $\\sigma$ is the volatility of the process, and $W_t$ is a Wiener process. We can discretize this process to get the following:\n",
        "$$x_{t+1} = x_t + \\theta(\\mu - x_t)dt + \\sigma \\sqrt{dt}\\mathcal{N}(0,1)$$\n",
        "Where $N(0,1)$ is a sample from the standard normal distribution. We will asume that our steps are of unit length, so we can simplify this to:\n",
        "$$x_{t+1} = x_t + \\theta(\\mu - x_t) + \\sigma \\mathcal{N}(0,1)$$\n",
        "We will use $\\theta = 0.15$, $\\mu = 0$, and $\\sigma = 0.2$. We will add this to our action in the following way\n",
        "$$a_t = \\min(\\max(\\mu(s_t) + x_t, -1), 1)$$\n",
        "Where $a_t$ is the action taken by the agent, $\\mu(s_t)$ is the action selected by the actor, and $x_t$ is the noise generated by the Ornstein-Uhlenbeck process.\n",
        "Please implement the `OU_Noise` class in DDPG.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC7QM6nbUKKL"
      },
      "source": [
        "## DDPG (3 points total)\n",
        "We will be implementing the DDPG algorithm. The DDPG algorithm is a model free, off policy algorithm that combines the actor-critic architecture with the insights of DQN. The algorithm is as follows:\n",
        "![DDPG](DDPG.png)\n",
        "Fill in both of the TODO in the `DDPG` class in DDPG.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLFvkExsZYk0"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk2I4FKvdGvq"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"inverted-double-pendulum-ddpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uANt1728UKKT",
        "outputId": "86ee897d-5d06-4d39-d913-d5c31d5718ef"
      },
      "outputs": [],
      "source": [
        "import DDPG\n",
        "import utils\n",
        "t = DDPG.DDPG(env,\n",
        "            model.Actor,\n",
        "            model.Critic,\n",
        "            use_wandb=True,\n",
        "            save_path = utils.get_save_path(\"DDPG\",\"./runs/\"))\n",
        "\n",
        "t.train(10000,\n",
        "        100,\n",
        "        100,\n",
        "        1000,\n",
        "        100,\n",
        "        1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM6cg3oBUKKU"
      },
      "source": [
        "Like what we did for the DQN, we can also animate one episode of the agent in the DoublePendulum environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KhZW0YAiUKKU",
        "outputId": "97c3d473-c2d1-4847-9915-c917f452f916"
      },
      "outputs": [],
      "source": [
        "total_rewards, frames = t.play_episode(0,True,42,eval_env)\n",
        "anim = animate(frames)\n",
        "print(total_rewards)\n",
        "HTML(anim.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDX_-QaXUKKV"
      },
      "source": [
        "As we can see, the agent is able to balance the double pendulum and it eventually reaches the equilibrium. However this equilibrium is not a stable equilibrium, so lets see how this model performs with perturbations. To do this, we will perturbe the model every 49 steps with a large input of $\\pm 0.75$ N to the cart. We will see how the model performs with this perturbation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLVtiLK0UKKa",
        "outputId": "8ad2d502-b3b8-4b0f-8457-ec9b942b2b8c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "frames = []\n",
        "scores = 0\n",
        "(s, _), done, ret = eval_env.reset(seed = 42\n",
        "                                   ), False, 0\n",
        "t.actor.eval()\n",
        "S = []\n",
        "outputs = []\n",
        "# s, r, terminated, truncated, info = eval_env.step(3)\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "    while not done:\n",
        "        # if random.random() < 0.1:\n",
        "        #     action = random.randint(0,4)\n",
        "        # else:\n",
        "        frames.append(eval_env.render())\n",
        "        output = t.actor(torch.tensor(s).unsqueeze(0).to(\"cpu\").float())\n",
        "        i+=1\n",
        "        if i%50 == 49:\n",
        "            output += 0.75*(np.sign(torch.randn_like(output)))\n",
        "        s_prime, r, terminated, truncated, info = eval_env.step(output.cpu().numpy().squeeze(0))\n",
        "        s = s_prime\n",
        "        ret += r\n",
        "        done = terminated or truncated\n",
        "\n",
        "scores += ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xP39icFmUKKf",
        "outputId": "3e9ca543-d542-423c-c335-3b0e0ada2a1e"
      },
      "outputs": [],
      "source": [
        "anim = animate(frames)\n",
        "print(total_rewards)\n",
        "HTML(anim.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQhwG0wEUKKl"
      },
      "source": [
        "You should see that the model is able to recover from the perturbation and is able to balance the double pendulum."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
